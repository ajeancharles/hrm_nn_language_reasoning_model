{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "469456c2-de22-463e-828f-d101a34b4ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 8279-5E6A\n",
      "\n",
      " Directory of C:\\Users\\ajean\\Downloads\\project3\n",
      "\n",
      "08/25/2025  04:59 PM    <DIR>          .\n",
      "08/25/2025  04:43 PM    <DIR>          ..\n",
      "08/25/2025  04:59 PM    <DIR>          .ipynb_checkpoints\n",
      "08/25/2025  04:45 PM    <DIR>          cache\n",
      "08/25/2025  04:44 PM    <DIR>          checkpoints\n",
      "08/25/2025  04:56 PM    <DIR>          config\n",
      "08/25/2025  04:44 PM    <DIR>          data\n",
      "08/25/2025  04:44 PM    <DIR>          logs\n",
      "08/25/2025  04:44 PM    <DIR>          models\n",
      "08/25/2025  04:45 PM    <DIR>          src\n",
      "08/25/2025  04:59 PM                72 Untitled.ipynb\n",
      "               1 File(s)             72 bytes\n",
      "              10 Dir(s)  1,464,672,505,856 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "76b6cda3-3c38-4e44-acb0-64f01066aa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7ee22d8d-1c08-4bc4-9d01-7b49398582d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.config_loader import load_config as load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0ca88054-22e8-4a06-8edd-d6dcbcb55f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  config.config_loader  import ConfigLoader as ConfigLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5eaa4493-0d71-4b67-9377-1a06ab3e21fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_loader =   load_config('C:\\\\Users\\\\ajean\\\\Downloads\\\\project3\\\\config\\\\hrm_config.yaml')\n",
    "#config_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0f6ba795-2dcf-486f-b364-dd67905cd77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load main configuration\n",
    "config = load_config(\"config/hrm_config.yaml\")\n",
    "#config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "72e7fd2a-9527-47a4-9ad8-1cb88eb20087",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = load_config(\"config/train_config.yaml\")\n",
    "inference_config = load_config(\"config/inference_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "906dc4be-83a8-439f-b9d4-f15481d256e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_config\n",
    "#inference_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7196ce15-6b3d-4871-bab6-db39bdf62d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  config.config_validator  import ConfigValidator as ConfigValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ef8d2ee2-c3ba-4be6-8a87-0486c80d081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_hrm_system(config_path: str, ignore_warnings: bool = True):\n",
    "    \"\"\"Initialize HRM system with improved error handling\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Check if config file exists\n",
    "        if not os.path.exists(config_path):\n",
    "            print(f\"Configuration file not found: {config_path}\")\n",
    "            print(\"Creating default configuration file...\")\n",
    "            create_hrm_config_file()\n",
    "            create_placeholder_data_files()\n",
    "        \n",
    "        # Load configuration\n",
    "        print(f\"Loading configuration from: {config_path}\")\n",
    "        config = load_config(config_path)\n",
    "        print(\"✓ Configuration loaded successfully\")\n",
    "        \n",
    "        # Validate configuration\n",
    "        print(\"Validating configuration...\")\n",
    "        validator = ConfigValidator()\n",
    "        errors = validator.validate(config)\n",
    "        \n",
    "        if errors:\n",
    "            print(\"Configuration validation results:\")\n",
    "            warnings = []\n",
    "            critical_errors = []\n",
    "            \n",
    "            for error in errors:\n",
    "                if error.startswith(\"Warning:\"):\n",
    "                    warnings.append(error)\n",
    "                    print(f\"  ⚠️  {error}\")\n",
    "                else:\n",
    "                    critical_errors.append(error)\n",
    "                    print(f\"  ❌ {error}\")\n",
    "            \n",
    "            if critical_errors and not ignore_warnings:\n",
    "                print(f\"\\nFound {len(critical_errors)} critical errors. Cannot proceed.\")\n",
    "                raise ValueError(\"Critical configuration errors found\")\n",
    "            elif critical_errors and ignore_warnings:\n",
    "                print(f\"\\nFound {len(critical_errors)} critical errors, but ignoring for testing...\")\n",
    "            else:\n",
    "                print(f\"\\nFound {len(warnings)} warnings, but no critical errors.\")\n",
    "        else:\n",
    "            print(\"✓ Configuration validation passed\")\n",
    "        \n",
    "        # Initialize system with validated config\n",
    "        print(\"Initializing HRM system...\")\n",
    "        system = HierarchicalReasoningSystem(config)\n",
    "        print(\"✓ HRM system initialized successfully\")\n",
    "        \n",
    "        return system\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"❌ File not found: {e}\")\n",
    "        print(\"Please run create_hrm_config_file() first to create the configuration\")\n",
    "        raise\n",
    "    except ValueError as e:\n",
    "        print(f\"❌ Configuration error: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error: {e}\")\n",
    "        raise\n",
    "\n",
    "# Enhanced HRM System class for testing\n",
    "class HierarchicalReasoningSystem:\n",
    "    \"\"\"Enhanced HRM system with better initialization feedback\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Dict[str, Any]):\n",
    "        self.config = config\n",
    "        self.initialized = False\n",
    "        \n",
    "        print(\"🚀 Initializing HRM System...\")\n",
    "        \n",
    "        # Display key configuration info\n",
    "        model_config = config.get('model', {})\n",
    "        arch_config = model_config.get('architecture', {})\n",
    "        layer_names = arch_config.get('layer_names', [])\n",
    "        \n",
    "        print(f\"   📊 Model layers: {layer_names}\")\n",
    "        print(f\"   📦 Number of layers: {len(layer_names)}\")\n",
    "        \n",
    "        training_config = config.get('training', {})\n",
    "        data_config = training_config.get('data', {})\n",
    "        batch_size = data_config.get('batch_size', 'N/A')\n",
    "        \n",
    "        print(f\"   🎯 Training batch size: {batch_size}\")\n",
    "        \n",
    "        # Check enabled data sources\n",
    "        data_sources = config.get('data_sources', {})\n",
    "        enabled_sources = [name for name, conf in data_sources.items() \n",
    "                          if isinstance(conf, dict) and conf.get('enabled', False)]\n",
    "        print(f\"   📁 Enabled data sources: {enabled_sources}\")\n",
    "        \n",
    "        self.initialized = True\n",
    "        print(\"✅ HRM System initialization complete\")\n",
    "    \n",
    "    def get_summary(self) -> str:\n",
    "        \"\"\"Get a summary of the system configuration\"\"\"\n",
    "        if not self.initialized:\n",
    "            return \"System not initialized\"\n",
    "        \n",
    "        summary = []\n",
    "        summary.append(\"=== HRM System Summary ===\")\n",
    "        summary.append(f\"System: {self.config['system']['name']} v{self.config['system']['version']}\")\n",
    "        summary.append(f\"Mode: {self.config['system']['mode']}\")\n",
    "        \n",
    "        layer_names = self.config['model']['architecture']['layer_names']\n",
    "        summary.append(f\"Architecture: {len(layer_names)} layers ({', '.join(layer_names)})\")\n",
    "        \n",
    "        return \"\\n\".join(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddac3abc-7c5a-4aa2-b0a3-508821bcfe6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "f386c09c-2c48-4d9b-b11d-db5c7feef114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created configuration file: config\\hrm_config.yaml\n"
     ]
    }
   ],
   "source": [
    "# Create the config directory and file\n",
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "def create_hrm_config_file():\n",
    "    \"\"\"Create the actual hrm_config.yaml file\"\"\"\n",
    "    \n",
    "    # Create config directory if it doesn't exist\n",
    "    config_dir = Path(\"config\")\n",
    "    config_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Define the configuration\n",
    "    config = {\n",
    "        'system': {\n",
    "            'name': 'Hierarchical Reasoning Model',\n",
    "            'version': '1.0.0',\n",
    "            'mode': 'training'\n",
    "        },\n",
    "        'model': {\n",
    "            'architecture': {\n",
    "                'num_layers': 6,\n",
    "                'layer_names': ['token', 'syntactic', 'semantic', 'discourse', 'pragmatic', 'reasoning']\n",
    "            },\n",
    "            'layers': {\n",
    "                'token': {\n",
    "                    'hidden_dim': 768,\n",
    "                    'embedding_dim': 768,\n",
    "                    'vocab_size': 50000,\n",
    "                    'max_sequence_length': 512,\n",
    "                    'dropout': 0.1\n",
    "                },\n",
    "                'syntactic': {\n",
    "                    'hidden_dim': 768,\n",
    "                    'num_attention_heads': 12,\n",
    "                    'parser_type': 'dependency',\n",
    "                    'grammar_rules_path': 'data/grammar_rules.json'\n",
    "                },\n",
    "                'semantic': {\n",
    "                    'hidden_dim': 1024,\n",
    "                    'entity_embedding_dim': 300,\n",
    "                    'entity_types': ['PERSON', 'ORG', 'LOC', 'MISC'],\n",
    "                    'knowledge_graph_path': 'data/knowledge_graph.pkl'\n",
    "                },\n",
    "                'discourse': {\n",
    "                    'hidden_dim': 768,\n",
    "                    'context_window': 10,\n",
    "                    'coreference_resolver': True,\n",
    "                    'discourse_markers_path': 'data/discourse_markers.txt'\n",
    "                },\n",
    "                'pragmatic': {\n",
    "                    'hidden_dim': 512,\n",
    "                    'intent_classes': ['question', 'statement', 'request', 'command'],\n",
    "                    'world_knowledge_db': 'data/world_knowledge.db'\n",
    "                },\n",
    "                'reasoning': {\n",
    "                    'hidden_dim': 1024,\n",
    "                    'reasoning_types': ['deductive', 'inductive', 'abductive', 'causal'],\n",
    "                    'max_reasoning_steps': 10,\n",
    "                    'confidence_threshold': 0.8\n",
    "                }\n",
    "            },\n",
    "            'communication': {\n",
    "                'upward_attention_dim': 256,\n",
    "                'downward_attention_dim': 256,\n",
    "                'bidirectional': True,\n",
    "                'residual_connections': True\n",
    "            }\n",
    "        },\n",
    "        'training': {\n",
    "            'data': {\n",
    "                'batch_size': 32,\n",
    "                'max_sequence_length': 512,\n",
    "                'train_split': 0.8,\n",
    "                'val_split': 0.1,\n",
    "                'test_split': 0.1\n",
    "            },\n",
    "            'phases': {\n",
    "                'layerwise_pretraining': {\n",
    "                    'enabled': True,\n",
    "                    'epochs_per_layer': 10,\n",
    "                    'learning_rate': 0.0001\n",
    "                },\n",
    "                'end_to_end_finetuning': {\n",
    "                    'enabled': True,\n",
    "                    'epochs': 50,\n",
    "                    'learning_rate': 0.00005,\n",
    "                    'warmup_steps': 1000\n",
    "                }\n",
    "            },\n",
    "            'loss': {\n",
    "                'layer_weights': [0.1, 0.15, 0.2, 0.2, 0.2, 0.15],\n",
    "                'reasoning_chain_weight': 0.3,\n",
    "                'explanation_weight': 0.2\n",
    "            },\n",
    "            'optimizer': {\n",
    "                'type': 'adamw',\n",
    "                'weight_decay': 0.01,\n",
    "                'gradient_clipping': 1.0\n",
    "            },\n",
    "            'checkpointing': {\n",
    "                'save_every': 1000,\n",
    "                'keep_best': 5,\n",
    "                'save_path': 'checkpoints/'\n",
    "            }\n",
    "        },\n",
    "        'data_sources': {\n",
    "            'wikipedia': {\n",
    "                'enabled': False,  # Disabled for testing\n",
    "                'path': 'data/wikipedia_dump.xml',\n",
    "                'max_articles': 100000\n",
    "            },\n",
    "            'books': {\n",
    "                'enabled': False,  # Disabled for testing\n",
    "                'path': 'data/gutenberg_books/',\n",
    "                'max_books': 1000\n",
    "            },\n",
    "            'qa_datasets': {\n",
    "                'squad': {\n",
    "                    'enabled': False,  # Disabled for testing\n",
    "                    'path': 'data/squad_v2.json'\n",
    "                }\n",
    "            },\n",
    "            'test_data': {\n",
    "                'enabled': True,  # Simple test data source\n",
    "                'path': 'data/test_data.txt'\n",
    "            }\n",
    "        },\n",
    "        'inference': {\n",
    "            'beam_size': 5,\n",
    "            'max_generation_length': 200,\n",
    "            'temperature': 0.7,\n",
    "            'top_p': 0.9,\n",
    "            'explanation_detail': 'medium'\n",
    "        },\n",
    "        'paths': {\n",
    "            'data_dir': 'data/',\n",
    "            'model_dir': 'models/',\n",
    "            'checkpoint_dir': 'checkpoints/',\n",
    "            'log_dir': 'logs/',\n",
    "            'cache_dir': 'cache/'\n",
    "        },\n",
    "        'logging': {\n",
    "            'level': 'INFO',\n",
    "            'file': 'logs/hrm.log',\n",
    "            'console': True\n",
    "        },\n",
    "        'hardware': {\n",
    "            'device': 'auto',\n",
    "            'mixed_precision': True,\n",
    "            'gradient_accumulation_steps': 4\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Write the configuration file\n",
    "    config_file = config_dir / \"hrm_config.yaml\"\n",
    "    with open(config_file, 'w') as f:\n",
    "        yaml.dump(config, f, default_flow_style=False, indent=2)\n",
    "    \n",
    "    print(f\"Created configuration file: {config_file}\")\n",
    "    return config_file\n",
    "\n",
    "# Create the config file\n",
    "config_file_path = create_hrm_config_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f8d1200c-0348-42f5-9327-aa71f4860184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created test data file: data\\test_data.txt\n",
      "Created directory: models\n",
      "Created directory: checkpoints\n",
      "Created directory: logs\n",
      "Created directory: cache\n"
     ]
    }
   ],
   "source": [
    "# Create placeholder data files to satisfy validation\n",
    "def create_placeholder_data_files():\n",
    "    \"\"\"Create placeholder data files for testing\"\"\"\n",
    "    \n",
    "    # Create data directory\n",
    "    data_dir = Path(\"data\")\n",
    "    data_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Create test data file\n",
    "    test_data_file = data_dir / \"test_data.txt\"\n",
    "    with open(test_data_file, 'w') as f:\n",
    "        f.write(\"This is a test sentence for HRM training.\\n\")\n",
    "        f.write(\"The sun rises in the east and sets in the west.\\n\")\n",
    "        f.write(\"Machine learning models require large amounts of training data.\\n\")\n",
    "    \n",
    "    print(f\"Created test data file: {test_data_file}\")\n",
    "    \n",
    "    # Create other required directories\n",
    "    for dir_name in ['models', 'checkpoints', 'logs', 'cache']:\n",
    "        dir_path = Path(dir_name)\n",
    "        dir_path.mkdir(exist_ok=True)\n",
    "        print(f\"Created directory: {dir_path}\")\n",
    "\n",
    "# Create the data files\n",
    "create_placeholder_data_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c1f6e002-2cf2-4d63-8164-b602262aba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed configuration loader that handles missing files gracefully\n",
    "import yaml\n",
    "import os\n",
    "from typing import Dict, Any\n",
    "from pathlib import Path\n",
    "\n",
    "def load_config(config_path: str) -> Dict[str, Any]:\n",
    "    \"\"\"Load configuration file with error handling\"\"\"\n",
    "    \n",
    "    config_file = Path(config_path)\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not config_file.exists():\n",
    "        raise FileNotFoundError(f\"Configuration file not found: {config_path}\")\n",
    "    \n",
    "    try:\n",
    "        with open(config_file, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "            \n",
    "        if config is None:\n",
    "            raise ValueError(\"Configuration file is empty or invalid\")\n",
    "            \n",
    "        return config\n",
    "        \n",
    "    except yaml.YAMLError as e:\n",
    "        raise ValueError(f\"Invalid YAML in configuration file: {e}\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error loading configuration: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0f274e83-d562-4f6f-a36b-6536dd0794ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing HRM System Setup\n",
      "==================================================\n",
      "Loading configuration from: config/hrm_config.yaml\n",
      "✓ Configuration loaded successfully\n",
      "Validating configuration...\n",
      "✓ Configuration validation passed\n",
      "Initializing HRM system...\n",
      "🚀 Initializing HRM System...\n",
      "   📊 Model layers: ['token', 'syntactic', 'semantic', 'discourse', 'pragmatic', 'reasoning']\n",
      "   📦 Number of layers: 6\n",
      "   🎯 Training batch size: 32\n",
      "   📁 Enabled data sources: ['test_data']\n",
      "✅ HRM System initialization complete\n",
      "✓ HRM system initialized successfully\n",
      "\n",
      "=== HRM System Summary ===\n",
      "System: Hierarchical Reasoning Model v1.0.0\n",
      "Mode: training\n",
      "Architecture: 6 layers (token, syntactic, semantic, discourse, pragmatic, reasoning)\n",
      "\n",
      "✅ All tests passed! The HRM system is ready.\n"
     ]
    }
   ],
   "source": [
    "# Test the complete system\n",
    "def test_hrm_system():\n",
    "    \"\"\"Test the complete HRM system setup\"\"\"\n",
    "    \n",
    "    print(\"🧪 Testing HRM System Setup\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Initialize the system (will create files if they don't exist)\n",
    "        system = initialize_hrm_system(\"config/hrm_config.yaml\", ignore_warnings=True)\n",
    "        \n",
    "        # Print system summary\n",
    "        print(\"\\n\" + system.get_summary())\n",
    "        \n",
    "        print(\"\\n✅ All tests passed! The HRM system is ready.\")\n",
    "        return system\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Test failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run the test\n",
    "system = test_hrm_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fe554b-5ac6-46ef-8715-e3fade6bf59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7521a39a-5a9f-4d5f-abda-9d4582a11d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
