{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Reasoning Model (Layers 0-5)\n",
    "\n",
    "This notebook demonstrates a conceptual implementation of a Hierarchical Reasoning Model (HRM). The model is structured into six distinct layers, from token-level processing up to meta-reasoning. Each layer builds upon the output of the previous one, creating a rich, multi-faceted analysis of the input text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "First, we import the necessary libraries. `dotenv` is used for loading environment variables, `os` for interacting with the operating system, `spacy` for linguistic features, and `openai` for interacting with the OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fc44377-e0a4-4658-819f-a1e564d34e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import spacy\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Configuration\n",
    "\n",
    "This section loads environment variables from a `.env` file. This is a secure way to manage sensitive information like API keys.\n",
    "\n",
    "**Note:** The cell below that changes the directory (`os.chdir`) contains a hardcoded path. This is for demonstration purposes and should be adapted for your own environment if you wish to run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7a707c6-9fd9-4cbe-a680-be4771a28c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "direct = r\"C:\\Users\\ajean\\Downloads\"\n",
    "os.chdir(direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "954504f6-39d1-4b4a-bdf2-ec1b456563a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # This loads variables from .env into os.environ\n",
    "\n",
    "endpoint = os.environ[\"OPENAI_EMBED_END_POINT\"]\n",
    "deployment = os.environ[\"OPENAI_EMBED_DEPLOYMENT\"]\n",
    "api_key = os.environ[\"OPENAI_EMBED_API_KEY\"]\n",
    "chat_model = os.environ[\"OPENAI_CHAT_DEPLOYMENT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining the HRM Layers\n",
    "\n",
    "Here we define the classes for each of the 6 layers in our hierarchical model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 0: Token Embedding Layer\n",
    "\n",
    "This is the foundational layer. It takes raw text as input and converts it into a numerical representation (embedding) using a pre-trained model from the OpenAI API. This embedding captures the semantic meaning of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ff98cce-34c9-4f01-8c8e-5ec6b2625c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Layer 0: Token Embeddings via OpenAI Embedding Endpoint ----------\n",
    "class TokenEmbeddingLayer:\n",
    "    def __init__(self):\n",
    "        endpoint = os.environ[\"OPENAI_EMBED_END_POINT\"] #\n",
    "        deployment = \"text-embedding-3-large\"\n",
    "        api_key = os.environ[\"OPENAI_EMBED_API_KEY\"] #\n",
    "        self.client = OpenAI(\n",
    "            base_url=endpoint.rstrip(\"/\") + \"/openai/v1/\",\n",
    "            api_key=api_key\n",
    "        )\n",
    "        self.deployment = deployment\n",
    "\n",
    "    def forward(self, text):\n",
    "        response = self.client.embeddings.create(\n",
    "            input=text,\n",
    "            model=self.deployment\n",
    "        )\n",
    "        return {\"embedding\": response.data[0].embedding}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 1: Syntax Layer\n",
    "\n",
    "The Syntax Layer processes the text to understand its grammatical structure. It uses the `spaCy` library to perform tasks like Part-of-Speech (POS) tagging and dependency parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6bbd0af9-75d3-47fa-9605-a1c79f9aac05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ---------- Layer 1: Syntax ----------\n",
    "class SyntaxLayer:\n",
    "    def __init__(self, spacy_model=\"en_core_web_sm\"):\n",
    "        self.nlp = spacy.load(spacy_model)\n",
    "\n",
    "    def forward(self, text):\n",
    "        doc = self.nlp(text)\n",
    "        syntax_info = [(tok.text, tok.pos_, tok.dep_, tok.head.text) for tok in doc]\n",
    "        return syntax_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 2: Semantic Layer\n",
    "\n",
    "This layer focuses on the meaning of the text. It performs Named Entity Recognition (NER) to identify real-world objects like people and places, and it attempts to extract basic relationships between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "semantic_layer_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Layer 2: Semantics ----------\n",
    "class SemanticLayer:\n",
    "    def __init__(self, spacy_model=\"en_core_web_sm\"):\n",
    "        self.nlp = spacy.load(spacy_model)\n",
    "\n",
    "    def forward(self, text):\n",
    "        doc = self.nlp(text)\n",
    "        entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "        relations = []\n",
    "        for tok in doc:\n",
    "            if tok.dep_ in (\"ROOT\", \"relcl\") and tok.pos_ == \"VERB\":\n",
    "                subj = [w.text for w in tok.lefts if w.dep_.startswith(\"nsubj\")]\n",
    "                obj = [w.text for w in tok.rights if w.dep_.startswith(\"dobj\")]\n",
    "                if subj and obj:\n",
    "                    relations.append((subj[0], tok.lemma_, obj[0]))\n",
    "        return {\"entities\": entities, \"relations\": relations}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 3: Discourse Layer\n",
    "\n",
    "The Discourse Layer analyzes how sentences and clauses are connected. It identifies discourse markers (e.g., 'because', 'however') and uses an OpenAI Chat model to perform coreference resolution (identifying when different words refer to the same entity, like 'John' and 'he')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discourse_layer_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Layer 3: Discourse + Coreference via OpenAI Chat API ----------\n",
    "class DiscourseLayer:\n",
    "    def __init__(self):\n",
    "        endpoint = os.environ[\"OPENAI_EMBED_END_POINT\"] # \n",
    "        api_key = os.environ[\"OPENAI_EMBED_API_KEY\"] # \n",
    "        chat_model = \"o4-mini\" # Replace with your actual chat deployment name\n",
    "        self.client = OpenAI(\n",
    "            base_url=endpoint.rstrip(\"/\") + \"/openai/v1/\",\n",
    "            api_key=api_key\n",
    "        )\n",
    "        self.model = chat_model\n",
    "        self.discourse_markers = [\n",
    "            \"however\", \"therefore\", \"because\", \"although\", \"furthermore\",\n",
    "            \"meanwhile\", \"then\", \"afterward\", \"but\", \"so\"\n",
    "        ]\n",
    "\n",
    "    def coreference_prompt(self, text):\n",
    "        return (\n",
    "            f\"Text: {text}\\n\"\n",
    "            \"Task: List all coreference clusters. For each cluster, show all mentions and explain what entity they refer to.\"\n",
    "        )\n",
    "\n",
    "    def forward(self, text):\n",
    "        tokens = text.split()\n",
    "        discourse_signals = [tok for tok in tokens if tok.lower() in self.discourse_markers]\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": self.coreference_prompt(text)}]\n",
    "        )\n",
    "        coref_result = response.choices[0].message.content\n",
    "        return {\n",
    "            \"coreferences\": coref_result,\n",
    "            \"discourse_markers\": discourse_signals\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 4: Pragmatic Layer\n",
    "\n",
    "This layer deals with the context-dependent meaning of the text. It uses an OpenAI Chat model to identify the speaker's intent and the real-world knowledge required to fully understand the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pragmatic_layer_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Layer 4: Pragmatics (Intent + World Knowledge via OpenAI Chat API) ----------\n",
    "class PragmaticLayer:\n",
    "    def __init__(self):\n",
    "        endpoint =  os.environ[\"OPENAI_EMBED_END_POINT\"] #  \n",
    "        api_key = os.environ[\"OPENAI_EMBED_API_KEY\"] # \n",
    "        chat_model = \"o4-mini\"\n",
    "        self.client = OpenAI(\n",
    "            base_url=endpoint.rstrip(\"/\") + \"/openai/v1/\",\n",
    "            api_key=api_key\n",
    "        )\n",
    "        self.model = chat_model\n",
    "\n",
    "    def pragmatics_prompt(self, text):\n",
    "        return (\n",
    "            f\"Text: {text}\\n\"\n",
    "            \"Task:\\n\"\n",
    "            \"1. Identify the main intent behind the text (the speaker’s goal, request, question, or communicative purpose).\\n\"\n",
    "            \"2. Summarize any background/world knowledge needed to fully understand or respond to the intent (include factual knowledge, context, norms, or relevant history if useful).\"\n",
    "        )\n",
    "\n",
    "    def forward(self, text):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": self.pragmatics_prompt(text)}]\n",
    "        )\n",
    "        pragmatic_result = response.choices[0].message.content\n",
    "        return {\n",
    "            \"pragmatic_analysis\": pragmatic_result\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer 5: Meta-Reasoning Layer\n",
    "\n",
    "This is the highest level of reasoning. It takes the outputs from all previous layers and performs a meta-analysis. This includes decomposing the overall goal of the text, generating a plan, and checking for logical consistency across the different layers of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meta_reasoning_layer_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Layer 5: Meta-Reasoning (Goal decomposition & planning) ----------\n",
    "class MetaReasoningLayer:\n",
    "    def __init__(self):\n",
    "        endpoint = os.environ[\"OPENAI_EMBED_END_POINT\"] # \n",
    "        api_key = os.environ[\"OPENAI_EMBED_API_KEY\"] #\n",
    "        chat_model = \"o4-mini\"\n",
    "        self.client = OpenAI(\n",
    "            base_url=endpoint.rstrip(\"/\") + \"/openai/v1/\",\n",
    "            api_key=api_key\n",
    "        )\n",
    "        self.model = chat_model\n",
    "\n",
    "    def metareasoning_prompt(self, text, outputs):\n",
    "        \"\"\"Prompt decomposes goals, plans steps, checks consistency across layers.\"\"\"\n",
    "        return (\n",
    "            f\"Original Text: {text}\\n\"\n",
    "            f\"Prior layer outputs:\\n{outputs}\\n\"\n",
    "            \"Task:\\n\"\n",
    "            \"1. Decompose the overall goal of this passage into explicit subgoals.\\n\"\n",
    "            \"2. Generate a reasoning or action plan—step by step.\\n\"\n",
    "            \"3. Analyze outputs above for logical consistency, completeness, or errors. Highlight any potential issues or corrections.\"\n",
    "        )\n",
    "\n",
    "    def forward(self, text, prev_outputs):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": self.metareasoning_prompt(text, prev_outputs)}]\n",
    "        )\n",
    "        meta_result = response.choices[0].message.content\n",
    "        return {\n",
    "            \"goal_decomposition\": meta_result\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasoning Tracker\n",
    "\n",
    "To maintain transparency, the `ReasoningTracker` class logs the inputs, outputs, and reasoning type at each step of the process. This allows us to create an auditable trace of the model's 'thought process'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasoning_tracker_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Reasoning Tracker ----------\n",
    "class ReasoningTracker:\n",
    "    def __init__(self):\n",
    "        self.chain = []\n",
    "\n",
    "    def log(self, layer, input_repr, output_repr, reason_type):\n",
    "        self.chain.append({\n",
    "            \"layer\": layer,\n",
    "            \"input\": str(input_repr),\n",
    "            \"output\": str(output_repr),\n",
    "            \"reason_type\": reason_type\n",
    "        })\n",
    "\n",
    "    def explain(self):\n",
    "        explanation = []\n",
    "        for step in self.chain:\n",
    "            explanation.append(\n",
    "                f\"[{step['layer']}] {step['reason_type']}: input={step['input']} → output={step['output']}\"\n",
    "            )\n",
    "        return \"\\n\".join(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. HRM Orchestrator and Demonstration\n",
    "\n",
    "The `HRM_L0toL5` class ties all the layers together into a single pipeline. The `process` method executes the forward pass through each layer sequentially.\n",
    "\n",
    "The `if __name__ == \"__main__\":` block provides a simple demonstration using a sample passage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3cd163ca-b411-4e3c-81e0-bdbdb1f1f063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Hierarchical Output Including Meta-Reasoning ===\n",
      "{'syntax': [('John', 'PROPN', 'nsubj', 'bought'), ('bought', 'VERB', 'ROOT', 'bought'), ('a', 'DET', 'det', 'car'), ('new', 'ADJ', 'amod', 'car'), ('car', 'NOUN', 'dobj', 'bought'), ('in', 'ADP', 'prep', 'bought'), ('New', 'PROPN', 'compound', 'York'), ('York', 'PROPN', 'pobj', 'in'), ('.', 'PUNCT', 'punct', 'bought'), ('He', 'PRON', 'nsubj', 'drove'), ('drove', 'VERB', 'ROOT', 'drove'), ('it', 'PRON', 'dobj', 'drove'), ('home', 'ADV', 'advmod', 'drove'), ('because', 'SCONJ', 'mark', 'was'), ('he', 'PRON', 'nsubj', 'was'), ('was', 'AUX', 'advcl', 'drove'), ('excited', 'ADJ', 'acomp', 'was'), ('.', 'PUNCT', 'punct', 'drove')], 'semantics': {'entities': [('John', 'PERSON'), ('New York', 'GPE')], 'relations': [('John', 'buy', 'car'), ('He', 'drive', 'it')]}, 'discourse': {'coreferences': 'Here are the coreference clusters in the text:\\n\\n1. Cluster 1 (the person)\\n   – Mentions:\\n     • “John” (sentence 1 subject)  \\n     • “He” (sentence 2 subject)  \\n     • “he” (in “because he was excited”)  \\n   – This cluster refers to the same individual, John.\\n\\n2. Cluster 2 (the vehicle)\\n   – Mentions:\\n     • “a new car” (the thing John bought)  \\n     • “it” (in “He drove it home”)  \\n   – This cluster refers to the car that John bought.', 'discourse_markers': ['because']}, 'pragmatics': {'pragmatic_analysis': '1. Main intent  \\nThe text’s primary purpose is to inform or narrate: it tells the reader that John purchased a new car in New York and then immediately drove it home because he was excited. There is no request or question—just a straightforward report of events and their causal link.\\n\\n2. Background/world knowledge  \\n• “John” refers to an individual with the legal ability to buy and drive a car (e.g., holding a driver’s license).  \\n• “New York” denotes a place (most likely the U.S. state or New York City) where car dealerships operate.  \\n• Buying a new car is commonly seen as an exciting milestone.  \\n• “He drove it home” assumes John’s home is within driving distance and that he has insurance and registration sorted out.  \\n• Human emotions such as excitement often motivate immediate, pleasurable actions (here, taking the new car for a drive).'}, 'meta_reasoning': {'goal_decomposition': '1. Subgoals of the Passage  \\n   1. Introduce the actor (John).  \\n   2. State the purchase event (John bought a new car).  \\n   3. Specify the location of the purchase (in New York).  \\n   4. Convey John’s emotional state (he was excited).  \\n   5. Describe the follow-up action (he drove the car home).  \\n\\n2. Reasoning/Action Plan (John’s steps)  \\n   1. Decide that he wants or needs a new car.  \\n   2. Research or choose a dealership in New York.  \\n   3. Travel to New York (if he was not already there).  \\n   4. Select and negotiate the purchase of a new car.  \\n   5. Complete the transaction (payment, paperwork).  \\n   6. Experience excitement about his new vehicle.  \\n   7. Immediately drive the car home.  \\n\\n3. Analysis of the Layered Outputs  \\n   A. Syntax  \\n      • Generally correct labeling of subjects, objects, modifiers, and the two roots (“bought” and “drove”).  \\n      • Minor point: “home” is tagged as ADV/advmod, which is acceptable but some schemes treat “home” as a noun in an adverbial PP.  \\n   B. Semantics  \\n      • Entities extracted: John (PERSON), New York (GPE).  \\n      • Missing extraction: “a new car” could be identified as a PRODUCT or VEHICLE entity.  \\n      • Relations captured: (John, buy, car) and (He, drive, it).  \\n         – It would be more consistent to resolve “He” to “John” and “it” to “the car,” yielding (John, drive, car).  \\n      • Causal link (“drove… because he was excited”) is not recorded as a semantic relation. A relation like (drive, cause, excited) or (John, motivated_by, excitement) could be added.  \\n   C. Discourse  \\n      • Coreference clusters correctly group John/He/he and a new car/it.  \\n      • Discourse marker “because” is identified.  \\n      • No major issues here.  \\n   D. Pragmatics  \\n      • Main intent (simple narration) is correctly identified.  \\n      • Background knowledge points are reasonable, though details about insurance/registration are hypothetical assumptions.  \\n      • No contradictions, but pragmatics could note the presupposition that driving license and home location are in range.  \\n\\nSummary of Corrections  \\n   - Add “car” (or “new car”) as an extracted entity in the semantics layer.  \\n   - Normalize pronoun relations so that “He” → “John” and “it” → “the car.”  \\n   - Introduce a semantic relation for causality (“drove because he was excited”).  \\n   - Optionally refine the syntactic function of “home” if a different annotation scheme is used.'}}\n",
      "\n",
      "=== Reasoning Trace ===\n",
      "[Layer 0: Tokens] embedding generated: input=John bought a new car in New York. He drove it home because he was excited. → output=[embedding omitted]\n",
      "[Layer 1: Syntax] parse dependencies: input=John bought a new car in New York. He drove it home because he was excited. → output=[('John', 'PROPN', 'nsubj', 'bought'), ('bought', 'VERB', 'ROOT', 'bought'), ('a', 'DET', 'det', 'car'), ('new', 'ADJ', 'amod', 'car'), ('car', 'NOUN', 'dobj', 'bought'), ('in', 'ADP', 'prep', 'bought'), ('New', 'PROPN', 'compound', 'York'), ('York', 'PROPN', 'pobj', 'in'), ('.', 'PUNCT', 'punct', 'bought'), ('He', 'PRON', 'nsubj', 'drove'), ('drove', 'VERB', 'ROOT', 'drove'), ('it', 'PRON', 'dobj', 'drove'), ('home', 'ADV', 'advmod', 'drove'), ('because', 'SCONJ', 'mark', 'was'), ('he', 'PRON', 'nsubj', 'was'), ('was', 'AUX', 'advcl', 'drove'), ('excited', 'ADJ', 'acomp', 'was'), ('.', 'PUNCT', 'punct', 'drove')]\n",
      "[Layer 2: Semantics] extract entities/relations: input=John bought a new car in New York. He drove it home because he was excited. → output={'entities': [('John', 'PERSON'), ('New York', 'GPE')], 'relations': [('John', 'buy', 'car'), ('He', 'drive', 'it')]}\n",
      "[Layer 3: Discourse] coreference: input=John bought a new car in New York. He drove it home because he was excited. → output={'coreferences': 'Here are the coreference clusters in the text:\\n\\n1. Cluster 1 (the person)\\n   – Mentions:\\n     • “John” (sentence 1 subject)  \\n     • “He” (sentence 2 subject)  \\n     • “he” (in “because he was excited”)  \\n   – This cluster refers to the same individual, John.\\n\\n2. Cluster 2 (the vehicle)\\n   – Mentions:\\n     • “a new car” (the thing John bought)  \\n     • “it” (in “He drove it home”)  \\n   – This cluster refers to the car that John bought.', 'discourse_markers': ['because']}\n",
      "[Layer 4: Pragmatics] intent & world knowledge: input=John bought a new car in New York. He drove it home because he was excited. → output={'pragmatic_analysis': '1. Main intent  \\nThe text’s primary purpose is to inform or narrate: it tells the reader that John purchased a new car in New York and then immediately drove it home because he was excited. There is no request or question—just a straightforward report of events and their causal link.\\n\\n2. Background/world knowledge  \\n• “John” refers to an individual with the legal ability to buy and drive a car (e.g., holding a driver’s license).  \\n• “New York” denotes a place (most likely the U.S. state or New York City) where car dealerships operate.  \\n• Buying a new car is commonly seen as an exciting milestone.  \\n• “He drove it home” assumes John’s home is within driving distance and that he has insurance and registration sorted out.  \\n• Human emotions such as excitement often motivate immediate, pleasurable actions (here, taking the new car for a drive).'}\n",
      "[Layer 5: Meta-Reasoning] goal decomposition, planning, consistency check: input=John bought a new car in New York. He drove it home because he was excited. → output={'goal_decomposition': '1. Subgoals of the Passage  \\n   1. Introduce the actor (John).  \\n   2. State the purchase event (John bought a new car).  \\n   3. Specify the location of the purchase (in New York).  \\n   4. Convey John’s emotional state (he was excited).  \\n   5. Describe the follow-up action (he drove the car home).  \\n\\n2. Reasoning/Action Plan (John’s steps)  \\n   1. Decide that he wants or needs a new car.  \\n   2. Research or choose a dealership in New York.  \\n   3. Travel to New York (if he was not already there).  \\n   4. Select and negotiate the purchase of a new car.  \\n   5. Complete the transaction (payment, paperwork).  \\n   6. Experience excitement about his new vehicle.  \\n   7. Immediately drive the car home.  \\n\\n3. Analysis of the Layered Outputs  \\n   A. Syntax  \\n      • Generally correct labeling of subjects, objects, modifiers, and the two roots (“bought” and “drove”).  \\n      • Minor point: “home” is tagged as ADV/advmod, which is acceptable but some schemes treat “home” as a noun in an adverbial PP.  \\n   B. Semantics  \\n      • Entities extracted: John (PERSON), New York (GPE).  \\n      • Missing extraction: “a new car” could be identified as a PRODUCT or VEHICLE entity.  \\n      • Relations captured: (John, buy, car) and (He, drive, it).  \\n         – It would be more consistent to resolve “He” to “John” and “it” to “the car,” yielding (John, drive, car).  \\n      • Causal link (“drove… because he was excited”) is not recorded as a semantic relation. A relation like (drive, cause, excited) or (John, motivated_by, excitement) could be added.  \\n   C. Discourse  \\n      • Coreference clusters correctly group John/He/he and a new car/it.  \\n      • Discourse marker “because” is identified.  \\n      • No major issues here.  \\n   D. Pragmatics  \\n      • Main intent (simple narration) is correctly identified.  \\n      • Background knowledge points are reasonable, though details about insurance/registration are hypothetical assumptions.  \\n      • No contradictions, but pragmatics could note the presupposition that driving license and home location are in range.  \\n\\nSummary of Corrections  \\n   - Add “car” (or “new car”) as an extracted entity in the semantics layer.  \\n   - Normalize pronoun relations so that “He” → “John” and “it” → “the car.”  \\n   - Introduce a semantic relation for causality (“drove because he was excited”).  \\n   - Optionally refine the syntactic function of “home” if a different annotation scheme is used.'}\n"
     ]
    }
   ],
   "source": [
    "# ---------- Unified Hierarchical Modular Flow ----------\n",
    "class HRM_L0toL5:\n",
    "    def __init__(self):\n",
    "        self.layer0 = TokenEmbeddingLayer()\n",
    "        self.layer1 = SyntaxLayer()\n",
    "        self.layer2 = SemanticLayer()\n",
    "        self.layer3 = DiscourseLayer()\n",
    "        self.layer4 = PragmaticLayer()\n",
    "        self.layer5 = MetaReasoningLayer()\n",
    "        self.tracker = ReasoningTracker()\n",
    "\n",
    "    def process(self, text):\n",
    "        tokens = self.layer0.forward(text)\n",
    "        self.tracker.log(\"Layer 0: Tokens\", text, \"[embedding omitted]\", \"embedding generated\")\n",
    "\n",
    "        syntax = self.layer1.forward(text)\n",
    "        self.tracker.log(\"Layer 1: Syntax\", text, syntax, \"parse dependencies\")\n",
    "\n",
    "        semantics = self.layer2.forward(text)\n",
    "        self.tracker.log(\"Layer 2: Semantics\", text, semantics, \"extract entities/relations\")\n",
    "\n",
    "        discourse = self.layer3.forward(text)\n",
    "        self.tracker.log(\"Layer 3: Discourse\", text, discourse, \"coreference\")\n",
    "\n",
    "        pragmatics = self.layer4.forward(text)\n",
    "        self.tracker.log(\"Layer 4: Pragmatics\", text, pragmatics, \"intent & world knowledge\")\n",
    "\n",
    "        # For Layer 5, include all previous outputs for global planning and consistency checks\n",
    "        prev_outputs = {\n",
    "            \"syntax\": syntax,\n",
    "            \"semantics\": semantics,\n",
    "            \"discourse\": discourse,\n",
    "            \"pragmatics\": pragmatics\n",
    "        }\n",
    "        meta = self.layer5.forward(text, prev_outputs)\n",
    "        self.tracker.log(\"Layer 5: Meta-Reasoning\", text, meta, \"goal decomposition, planning, consistency check\")\n",
    "\n",
    "        return {\n",
    "            \"syntax\": syntax,\n",
    "            \"semantics\": semantics,\n",
    "            \"discourse\": discourse,\n",
    "            \"pragmatics\": pragmatics,\n",
    "            \"meta_reasoning\": meta\n",
    "        }\n",
    "\n",
    "# ---------- DEMO ----------\n",
    "if __name__ == \"__main__\":\n",
    "    model = HRM_L0toL5()\n",
    "    passage = \"John bought a new car in New York. He drove it home because he was excited.\"\n",
    "    final_output = model.process(passage)\n",
    "    print(\"=== Hierarchical Output Including Meta-Reasoning ===\")\n",
    "    print(final_output)\n",
    "    print(\"\\n=== Reasoning Trace ===\")\n",
    "    print(model.tracker.explain())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
